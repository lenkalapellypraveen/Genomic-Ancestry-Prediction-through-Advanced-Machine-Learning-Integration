In this project, I implemented a Ridge Regression model entirely from scratch to tackle the challenge of Ancestry Classification. This involved developing a custom algorithm capable of handling multiclass classification tasks by adjusting the regularization strength via the Ridge parameter to optimize model performance. 

The model was built using Python, leveraging numpy for mathematical operations to ensure efficient computation of the Ridge Regression formula. Key steps included the computation of gradient descent to minimize the loss function, which was regularized to prevent overfitting. Special attention was given to tuning the lambda parameter, which controls the strength of the regularization and plays a crucial role in balancing bias and variance. To validate the effectiveness of the model, I employed k-fold cross-validation, ensuring that the model generalizes well on unseen data while adjusting lambda values to find the optimal setting. 

This hands-on approach not only reinforced my understanding of fundamental machine learning concepts such as loss functions, regularization, and model evaluation but also honed my skills in Python programming and numerical computation. The project underscored the importance of careful parameter tuning and provided insights into the practical challenges of developing custom machine learning models for specific applications.
